{
    "name": "root",
    "gauges": {
        "MagCoop.Policy.Entropy.mean": {
            "value": 3.701531171798706,
            "min": 2.746622323989868,
            "max": 3.8807320594787598,
            "count": 100
        },
        "MagCoop.Policy.Entropy.sum": {
            "value": 36567.42578125,
            "min": 27600.806640625,
            "max": 39109.46875,
            "count": 100
        },
        "MagCoop.Step.mean": {
            "value": 999987.0,
            "min": 9921.0,
            "max": 999987.0,
            "count": 100
        },
        "MagCoop.Step.sum": {
            "value": 999987.0,
            "min": 9921.0,
            "max": 999987.0,
            "count": 100
        },
        "MagCoop.Policy.ExtrinsicValueEstimate.mean": {
            "value": 179.74073791503906,
            "min": -11.05767822265625,
            "max": 201.77479553222656,
            "count": 100
        },
        "MagCoop.Policy.ExtrinsicValueEstimate.sum": {
            "value": 15817.185546875,
            "min": -973.07568359375,
            "max": 17492.73046875,
            "count": 100
        },
        "MagCoop.Environment.EpisodeLength.mean": {
            "value": 505.75,
            "min": 190.78846153846155,
            "max": 622.9375,
            "count": 100
        },
        "MagCoop.Environment.EpisodeLength.sum": {
            "value": 10115.0,
            "min": 8699.0,
            "max": 11352.0,
            "count": 100
        },
        "MagCoop.Environment.CumulativeReward.mean": {
            "value": 1267.7107091903686,
            "min": 5.254382728076562,
            "max": 1560.1075315475464,
            "count": 100
        },
        "MagCoop.Environment.CumulativeReward.sum": {
            "value": 25354.214183807373,
            "min": 215.42969185113907,
            "max": 28456.672649383545,
            "count": 100
        },
        "MagCoop.Policy.ExtrinsicReward.mean": {
            "value": 1267.7107091903686,
            "min": 5.254382728076562,
            "max": 1560.1075315475464,
            "count": 100
        },
        "MagCoop.Policy.ExtrinsicReward.sum": {
            "value": 25354.214183807373,
            "min": 215.42969185113907,
            "max": 28456.672649383545,
            "count": 100
        },
        "MagCoop.Losses.PolicyLoss.mean": {
            "value": 0.058392513421959946,
            "min": 0.05241405150365751,
            "max": 0.07076833942704194,
            "count": 100
        },
        "MagCoop.Losses.PolicyLoss.sum": {
            "value": 0.9342802147513591,
            "min": 0.8910388755621776,
            "max": 1.2643742524907187,
            "count": 100
        },
        "MagCoop.Losses.ValueLoss.mean": {
            "value": 23.51808114134603,
            "min": 3.4739184686731477,
            "max": 1253.2102495978859,
            "count": 100
        },
        "MagCoop.Losses.ValueLoss.sum": {
            "value": 376.2892982615365,
            "min": 59.05661396744351,
            "max": 21434.6700398763,
            "count": 100
        },
        "MagCoop.Policy.LearningRate.mean": {
            "value": 1.3853120382624978e-06,
            "min": 1.3853120382624978e-06,
            "max": 0.0002984231652314941,
            "count": 100
        },
        "MagCoop.Policy.LearningRate.sum": {
            "value": 2.2164992612199964e-05,
            "min": 2.2164992612199964e-05,
            "max": 0.005210341863219399,
            "count": 100
        },
        "MagCoop.Policy.Epsilon.mean": {
            "value": 0.10046173750000001,
            "min": 0.10046173750000001,
            "max": 0.19947438823529412,
            "count": 100
        },
        "MagCoop.Policy.Epsilon.sum": {
            "value": 1.6073878000000001,
            "min": 1.6073878000000001,
            "max": 3.5367806,
            "count": 100
        },
        "MagCoop.Policy.Beta.mean": {
            "value": 4.689282624999995e-05,
            "min": 4.689282624999995e-05,
            "max": 0.007958003620000001,
            "count": 100
        },
        "MagCoop.Policy.Beta.sum": {
            "value": 0.0007502852199999992,
            "min": 0.0007502852199999992,
            "max": 0.13894876994,
            "count": 100
        },
        "MagCoop.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        },
        "MagCoop.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1740090227",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "E:\\anba\\envs\\Magister_unity\\Scripts\\mlagents-learn config/MoveToGoal1M.yaml --initialize-from=Forest_Solo --run-id=Desert_Solo --force",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.5.1+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1740095770"
    },
    "total": 5543.262834300011,
    "count": 1,
    "self": 0.01498629999696277,
    "children": {
        "run_training.setup": {
            "total": 0.10692970000673085,
            "count": 1,
            "self": 0.10692970000673085
        },
        "TrainerController.start_learning": {
            "total": 5543.140918300007,
            "count": 1,
            "self": 16.806941604678286,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.857258699994418,
                    "count": 1,
                    "self": 6.857258699994418
                },
                "TrainerController.advance": {
                    "total": 5519.3911197953275,
                    "count": 800962,
                    "self": 15.51347580870788,
                    "children": {
                        "env_step": {
                            "total": 5133.251114192055,
                            "count": 800962,
                            "self": 3449.869540401254,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1672.67838720094,
                                    "count": 800962,
                                    "self": 38.19285888974264,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1634.4855283111974,
                                            "count": 799110,
                                            "self": 1634.4855283111974
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 10.703186589860707,
                                    "count": 800962,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 5520.143069696336,
                                            "count": 800962,
                                            "is_parallel": true,
                                            "self": 2783.9716984010884,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0029821999924024567,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0006554999708896503,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0023267000215128064,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0023267000215128064
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 2736.1683890952554,
                                                    "count": 800962,
                                                    "is_parallel": true,
                                                    "self": 53.690222807679675,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 45.3880214929668,
                                                            "count": 800962,
                                                            "is_parallel": true,
                                                            "self": 45.3880214929668
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 2466.86835889722,
                                                            "count": 800962,
                                                            "is_parallel": true,
                                                            "self": 2466.86835889722
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 170.22178589738905,
                                                            "count": 800962,
                                                            "is_parallel": true,
                                                            "self": 109.93661778530804,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 60.28516811208101,
                                                                    "count": 1601924,
                                                                    "is_parallel": true,
                                                                    "self": 60.28516811208101
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 370.6265297945647,
                            "count": 800962,
                            "self": 19.965757992278668,
                            "children": {
                                "process_trajectory": {
                                    "total": 73.39044360218395,
                                    "count": 800962,
                                    "self": 65.37915510221501,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 8.011288499968941,
                                            "count": 100,
                                            "self": 8.011288499968941
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 277.2703282001021,
                                    "count": 1687,
                                    "self": 122.4185006985208,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 154.85182750158128,
                                            "count": 21186,
                                            "self": 154.85182750158128
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.00000761449337e-06,
                    "count": 1,
                    "self": 1.00000761449337e-06
                },
                "TrainerController._save_models": {
                    "total": 0.08559719999902882,
                    "count": 1,
                    "self": 0.010936099992250092,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.07466110000677872,
                            "count": 1,
                            "self": 0.07466110000677872
                        }
                    }
                }
            }
        }
    }
}